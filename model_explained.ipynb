{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the available csv files and by scraping data from the website besoccer.com, I have compiled a dataset of 161,112 football matches in 14 leagues with 55 columns of relevant information about them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Result', 'Season', 'Round', 'Teams_in_League',\n",
       "       'Home_Team_Goals_For_This_Far', 'Home_Team_Goals_Against_This_Far',\n",
       "       'Away_Team_Goals_For_This_Far', 'Away_Team_Goals_Against_This_Far',\n",
       "       'Home_Team_Points', 'Away_Team_Points', 'Home_Team_Losing_Streak',\n",
       "       'Away_Team_Losing_Streak', 'Home_Team_Winning_Streak',\n",
       "       'Away_Team_Winning_Streak', 'Home_Team_Unbeaten_Streak',\n",
       "       'Away_Team_Unbeaten_Streak', 'Elo_home', 'Elo_away',\n",
       "       'Home_Wins_This_Far', 'Home_Draws_This_Far', 'Home_Losses_This_Far',\n",
       "       'Away_Wins_This_Far', 'Away_Draws_This_Far', 'Away_Losses_This_Far',\n",
       "       'Home_Wins_This_Far_at_Home', 'Home_Draws_This_Far_at_Home',\n",
       "       'Home_Losses_This_Far_at_Home', 'Home_Wins_This_Far_Away',\n",
       "       'Home_Draws_This_Far_Away', 'Home_Losses_This_Far_Away',\n",
       "       'Away_Wins_This_Far_at_Home', 'Away_Draws_This_Far_at_Home',\n",
       "       'Away_Losses_This_Far_at_Home', 'Away_Wins_This_Far_Away',\n",
       "       'Away_Draws_This_Far_Away', 'Away_Losses_This_Far_Away', 'Capacity',\n",
       "       'Home_Yellow', 'Home_Team_Reds_This_Far', 'Home_Team_Yellows_This_Far',\n",
       "       'Away_Team_Reds_This_Far', 'Away_Team_Yellows_This_Far', 'Away_Red',\n",
       "       'Home_Points_Per_Game', 'Home_Goals_Per_Game',\n",
       "       'Home_Goals_Against_Per_Game', 'Home_Cards_Per_Game',\n",
       "       'Away_Points_Per_Game', 'Away_Goals_Per_Game',\n",
       "       'Away_Goals_Against_Per_Game', 'Away_Cards_Per_Game', 'Date_New',\n",
       "       'Link', 'Pitch_Match', 'League'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv('cleaned_dataset.csv')\n",
    "data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By training models in succession and by tuning their hyper-parameters it is possible to find a model which can use this information to accurately predict future results. Feature selection was used to resize the data to remove irrelevant columns which allows the model to train more quickly.\n",
    "\n",
    "Using a correlation metric gave the relevant columns as "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_cols = ['Season', 'Teams_in_League', 'Home_Team_Goals_For_This_Far',\n",
    "            'Home_Team_Goals_Against_This_Far', 'Away_Team_Goals_For_This_Far',\n",
    "            'Away_Team_Goals_Against_This_Far', 'Home_Team_Points',\n",
    "            'Away_Team_Points', 'Away_Team_Winning_Streak',\n",
    "            'Home_Team_Unbeaten_Streak', 'Away_Team_Unbeaten_Streak', 'Elo_home',\n",
    "            'Elo_away', 'Home_Wins_This_Far', 'Home_Draws_This_Far',\n",
    "            'Home_Losses_This_Far', 'Away_Draws_This_Far',\n",
    "            'Home_Wins_This_Far_at_Home', 'Home_Draws_This_Far_at_Home',\n",
    "            'Home_Losses_This_Far_at_Home', 'Home_Draws_This_Far_Away',\n",
    "            'Away_Wins_This_Far_at_Home', 'Away_Draws_This_Far_at_Home',\n",
    "            'Away_Losses_This_Far_at_Home', 'Away_Wins_This_Far_Away',\n",
    "            'Away_Draws_This_Far_Away', 'Capacity', 'Home_Yellow',\n",
    "            'Away_Team_Yellows_This_Far', 'Away_Red', 'Home_Points_Per_Game',\n",
    "            'Home_Goals_Per_Game', 'Home_Goals_Against_Per_Game',\n",
    "            'Away_Points_Per_Game', 'Away_Goals_Per_Game',\n",
    "            'Away_Goals_Against_Per_Game', 'Away_Cards_Per_Game', 'Pitch_Match',\n",
    "            'League']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "while using other metrics such as SelectKBest with a chi-squared function and RandomForest to sort feature importances produced similar lists. Using this one was purely due to it producing the best results on the testing set. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grid Search (particularly with the GridSearchCV package) was used to find the best model after separating the dataset into train and test sets and then scaling them with the StandardScaler package. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [LinearRegression(),\n",
    "    KNeighborsClassifier(n_neighbors=151),\n",
    "    MLPClassifier(hidden_layer_sizes=(150, 100, 50), max_iter=1000,\n",
    "                  activation='tanh', solver='adam', random_state=1,\n",
    "                  learning_rate='adaptive'),\n",
    "    MLPRegressor(activation='tanh', alpha=0.1,\n",
    "       hidden_layer_sizes=(150, 100, 50),\n",
    "       learning_rate='adaptive', solver='sgd',\n",
    "       max_iter=1000),\n",
    "    DecisionTreeClassifier(random_state=1,\n",
    "    max_features=\"sqrt\",\n",
    "    max_depth=None),\n",
    "    DecisionTreeRegressor(criterion='squared_error',\n",
    "    max_depth=5),\n",
    "    Lasso(alpha=0.00023),\n",
    "    AdaBoostClassifier(learning_rate=1.0, n_estimators=10000),\n",
    "    AdaBoostRegressor(learning_rate=0.01, n_estimators=10000),\n",
    "    RandomForestClassifier(\n",
    "        criterion='entropy', max_depth=128,\n",
    "        max_features='log2', n_estimators=1024),\n",
    "    RandomForestRegressor(criterion='poisson',\n",
    "    max_depth=12, max_features='log2',\n",
    "    n_estimators=256),\n",
    "    GradientBoostingClassifier(criterion='friedman_mse',\n",
    "                               learning_rate=0.2, loss='log_loss',\n",
    "                               max_depth=8, max_features='sqrt',\n",
    "                               min_samples_leaf=0.1,\n",
    "                               min_samples_split=0.18,\n",
    "                               n_estimators=10, subsample=1),\n",
    "    GradientBoostingRegressor(criterion='friedman_mse',\n",
    "    learning_rate=0.2, loss='squared_error',\n",
    "    max_depth=8, max_features='log2',\n",
    "    min_samples_leaf=0.1,\n",
    "    min_samples_split=0.18,\n",
    "    n_estimators=10, subsample=1),\n",
    "    XGBClassifier(learning_rate=0.01, max_depth=6, n_estimators=324),\n",
    "    XGBRegressor(learning_rate=0.05, max_depth=4, n_estimators=220),\n",
    "    SGDClassifier(alpha=0.01, loss='log_loss', penalty='none'),\n",
    "    SGDRegressor(alpha=0.01, loss='squared_error', penalty='none'),\n",
    "    RidgeClassifier()\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above are the best hyper-parameters by score after roughly a day of training each model. By score, the best models were RandomForestClassifier and XGBClassifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/hamish/AiCore/Football-Match-Outcome-Prediction/model_explained.ipynb Cell 9'\u001b[0m in \u001b[0;36m<cell line: 25>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/hamish/AiCore/Football-Match-Outcome-Prediction/model_explained.ipynb#ch0000010?line=20'>21</a>\u001b[0m X_train, X_test, y_train, y_test \u001b[39m=\u001b[39m train_test_split(X_sc, y, test_size\u001b[39m=\u001b[39m\u001b[39m0.1\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/hamish/AiCore/Football-Match-Outcome-Prediction/model_explained.ipynb#ch0000010?line=21'>22</a>\u001b[0m model \u001b[39m=\u001b[39m RandomForestClassifier(\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/hamish/AiCore/Football-Match-Outcome-Prediction/model_explained.ipynb#ch0000010?line=22'>23</a>\u001b[0m         criterion\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mentropy\u001b[39m\u001b[39m'\u001b[39m, max_depth\u001b[39m=\u001b[39m\u001b[39m128\u001b[39m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/hamish/AiCore/Football-Match-Outcome-Prediction/model_explained.ipynb#ch0000010?line=23'>24</a>\u001b[0m         max_features\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mlog2\u001b[39m\u001b[39m'\u001b[39m, n_estimators\u001b[39m=\u001b[39m\u001b[39m1024\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/hamish/AiCore/Football-Match-Outcome-Prediction/model_explained.ipynb#ch0000010?line=24'>25</a>\u001b[0m model \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit(X_train, y_train)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/hamish/AiCore/Football-Match-Outcome-Prediction/model_explained.ipynb#ch0000010?line=25'>26</a>\u001b[0m y_pred \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mpredict(X_test)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/hamish/AiCore/Football-Match-Outcome-Prediction/model_explained.ipynb#ch0000010?line=26'>27</a>\u001b[0m cm \u001b[39m=\u001b[39m confusion_matrix(y_test, y_pred)\n",
      "File \u001b[0;32m/opt/miniconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:465\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    460\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwarm_start \u001b[39mand\u001b[39;00m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mestimators_) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    461\u001b[0m     \u001b[39m# We draw from the random state to get the random state we\u001b[39;00m\n\u001b[1;32m    462\u001b[0m     \u001b[39m# would have got if we hadn't used a warm_start.\u001b[39;00m\n\u001b[1;32m    463\u001b[0m     random_state\u001b[39m.\u001b[39mrandint(MAX_INT, size\u001b[39m=\u001b[39m\u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mestimators_))\n\u001b[0;32m--> 465\u001b[0m trees \u001b[39m=\u001b[39m [\n\u001b[1;32m    466\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_make_estimator(append\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, random_state\u001b[39m=\u001b[39mrandom_state)\n\u001b[1;32m    467\u001b[0m     \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(n_more_estimators)\n\u001b[1;32m    468\u001b[0m ]\n\u001b[1;32m    470\u001b[0m \u001b[39m# Parallel loop: we prefer the threading backend as the Cython code\u001b[39;00m\n\u001b[1;32m    471\u001b[0m \u001b[39m# for fitting the trees is internally releasing the Python GIL\u001b[39;00m\n\u001b[1;32m    472\u001b[0m \u001b[39m# making threading more efficient than multiprocessing in\u001b[39;00m\n\u001b[1;32m    473\u001b[0m \u001b[39m# that case. However, for joblib 0.12+ we respect any\u001b[39;00m\n\u001b[1;32m    474\u001b[0m \u001b[39m# parallel_backend contexts set at a higher level,\u001b[39;00m\n\u001b[1;32m    475\u001b[0m \u001b[39m# since correctness does not rely on using threads.\u001b[39;00m\n\u001b[1;32m    476\u001b[0m trees \u001b[39m=\u001b[39m Parallel(\n\u001b[1;32m    477\u001b[0m     n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_jobs,\n\u001b[1;32m    478\u001b[0m     verbose\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    493\u001b[0m     \u001b[39mfor\u001b[39;00m i, t \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(trees)\n\u001b[1;32m    494\u001b[0m )\n",
      "File \u001b[0;32m/opt/miniconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:466\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    460\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwarm_start \u001b[39mand\u001b[39;00m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mestimators_) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    461\u001b[0m     \u001b[39m# We draw from the random state to get the random state we\u001b[39;00m\n\u001b[1;32m    462\u001b[0m     \u001b[39m# would have got if we hadn't used a warm_start.\u001b[39;00m\n\u001b[1;32m    463\u001b[0m     random_state\u001b[39m.\u001b[39mrandint(MAX_INT, size\u001b[39m=\u001b[39m\u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mestimators_))\n\u001b[1;32m    465\u001b[0m trees \u001b[39m=\u001b[39m [\n\u001b[0;32m--> 466\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_estimator(append\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m, random_state\u001b[39m=\u001b[39;49mrandom_state)\n\u001b[1;32m    467\u001b[0m     \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(n_more_estimators)\n\u001b[1;32m    468\u001b[0m ]\n\u001b[1;32m    470\u001b[0m \u001b[39m# Parallel loop: we prefer the threading backend as the Cython code\u001b[39;00m\n\u001b[1;32m    471\u001b[0m \u001b[39m# for fitting the trees is internally releasing the Python GIL\u001b[39;00m\n\u001b[1;32m    472\u001b[0m \u001b[39m# making threading more efficient than multiprocessing in\u001b[39;00m\n\u001b[1;32m    473\u001b[0m \u001b[39m# that case. However, for joblib 0.12+ we respect any\u001b[39;00m\n\u001b[1;32m    474\u001b[0m \u001b[39m# parallel_backend contexts set at a higher level,\u001b[39;00m\n\u001b[1;32m    475\u001b[0m \u001b[39m# since correctness does not rely on using threads.\u001b[39;00m\n\u001b[1;32m    476\u001b[0m trees \u001b[39m=\u001b[39m Parallel(\n\u001b[1;32m    477\u001b[0m     n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_jobs,\n\u001b[1;32m    478\u001b[0m     verbose\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    493\u001b[0m     \u001b[39mfor\u001b[39;00m i, t \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(trees)\n\u001b[1;32m    494\u001b[0m )\n",
      "File \u001b[0;32m/opt/miniconda3/lib/python3.9/site-packages/sklearn/ensemble/_base.py:186\u001b[0m, in \u001b[0;36mBaseEnsemble._make_estimator\u001b[0;34m(self, append, random_state)\u001b[0m\n\u001b[1;32m    183\u001b[0m             estimator\u001b[39m.\u001b[39mset_params(max_features\u001b[39m=\u001b[39m\u001b[39m1.0\u001b[39m)\n\u001b[1;32m    185\u001b[0m \u001b[39mif\u001b[39;00m random_state \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 186\u001b[0m     _set_random_states(estimator, random_state)\n\u001b[1;32m    188\u001b[0m \u001b[39mif\u001b[39;00m append:\n\u001b[1;32m    189\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mestimators_\u001b[39m.\u001b[39mappend(estimator)\n",
      "File \u001b[0;32m/opt/miniconda3/lib/python3.9/site-packages/sklearn/ensemble/_base.py:83\u001b[0m, in \u001b[0;36m_set_random_states\u001b[0;34m(estimator, random_state)\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[39mfor\u001b[39;00m key \u001b[39min\u001b[39;00m \u001b[39msorted\u001b[39m(estimator\u001b[39m.\u001b[39mget_params(deep\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)):\n\u001b[1;32m     82\u001b[0m     \u001b[39mif\u001b[39;00m key \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mrandom_state\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mor\u001b[39;00m key\u001b[39m.\u001b[39mendswith(\u001b[39m\"\u001b[39m\u001b[39m__random_state\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m---> 83\u001b[0m         to_set[key] \u001b[39m=\u001b[39m random_state\u001b[39m.\u001b[39;49mrandint(np\u001b[39m.\u001b[39;49miinfo(np\u001b[39m.\u001b[39;49mint32)\u001b[39m.\u001b[39;49mmax)\n\u001b[1;32m     85\u001b[0m \u001b[39mif\u001b[39;00m to_set:\n\u001b[1;32m     86\u001b[0m     estimator\u001b[39m.\u001b[39mset_params(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mto_set)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def scale_array(df):\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(df)\n",
    "    X_sc = scaler.transform(df)\n",
    "    return X_sc\n",
    "\n",
    "def accuracy(confusion_matrix):\n",
    "    diagonal_sum = confusion_matrix.trace()\n",
    "    sum_of_all_elements = confusion_matrix.sum()\n",
    "    return diagonal_sum / sum_of_all_elements\n",
    "\n",
    "y = data['Result'].values\n",
    "X = data.drop(['Result', 'Date_New', 'Link'], inplace=False, axis=1)\n",
    "X.League = X.League.astype('category').cat.codes\n",
    "X_sc = scale_array(X[svm_cols])\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_sc, y, test_size=0.1)\n",
    "model = RandomForestClassifier(\n",
    "        criterion='entropy', max_depth=128,\n",
    "        max_features='log2', n_estimators=1024)\n",
    "model = model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "print(accuracy(cm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This gave an accuracy of around 0.53 which is passable. Afterwards, I iteratively tested removing older years from the dataset as they ae unlikely to be reflective of modern football. Supported by testing, I decided to remove the matches played before the year 2000 and briefly trialed removing the eerste divisie before simply rescraping the data as it was poorly scraped initially."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3d597f4c481aa0f25dceb95d2a0067e73c0966dcbd003d741d821a7208527ecf"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
