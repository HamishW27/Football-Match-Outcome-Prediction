{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the available csv files and by scraping data from the website besoccer.com, I have compiled a dataset of 161,112 football matches in 14 leagues with 55 columns of relevant information about them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Result', 'Season', 'Round', 'Teams_in_League',\n",
       "       'Home_Team_Goals_For_This_Far', 'Home_Team_Goals_Against_This_Far',\n",
       "       'Away_Team_Goals_For_This_Far', 'Away_Team_Goals_Against_This_Far',\n",
       "       'Home_Team_Points', 'Away_Team_Points', 'Home_Team_Losing_Streak',\n",
       "       'Away_Team_Losing_Streak', 'Home_Team_Winning_Streak',\n",
       "       'Away_Team_Winning_Streak', 'Home_Team_Unbeaten_Streak',\n",
       "       'Away_Team_Unbeaten_Streak', 'Elo_home', 'Elo_away',\n",
       "       'Home_Wins_This_Far', 'Home_Draws_This_Far', 'Home_Losses_This_Far',\n",
       "       'Away_Wins_This_Far', 'Away_Draws_This_Far', 'Away_Losses_This_Far',\n",
       "       'Home_Wins_This_Far_at_Home', 'Home_Draws_This_Far_at_Home',\n",
       "       'Home_Losses_This_Far_at_Home', 'Home_Wins_This_Far_Away',\n",
       "       'Home_Draws_This_Far_Away', 'Home_Losses_This_Far_Away',\n",
       "       'Away_Wins_This_Far_at_Home', 'Away_Draws_This_Far_at_Home',\n",
       "       'Away_Losses_This_Far_at_Home', 'Away_Wins_This_Far_Away',\n",
       "       'Away_Draws_This_Far_Away', 'Away_Losses_This_Far_Away', 'Capacity',\n",
       "       'Home_Yellow', 'Home_Team_Reds_This_Far', 'Home_Team_Yellows_This_Far',\n",
       "       'Away_Team_Reds_This_Far', 'Away_Team_Yellows_This_Far', 'Away_Red',\n",
       "       'Home_Points_Per_Game', 'Home_Goals_Per_Game',\n",
       "       'Home_Goals_Against_Per_Game', 'Home_Cards_Per_Game',\n",
       "       'Away_Points_Per_Game', 'Away_Goals_Per_Game',\n",
       "       'Away_Goals_Against_Per_Game', 'Away_Cards_Per_Game', 'Date_New',\n",
       "       'Link', 'Pitch_Match', 'League'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv('cleaned_dataset.csv')\n",
    "data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By training models in succession and by tuning their hyper-parameters it is possible to find a model which can use this information to accurately predict future results. Feature selection was used to resize the data to remove irrelevant columns which allows the model to train more quickly.\n",
    "\n",
    "Using a correlation metric gave the relevant columns as "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_cols = ['Season', 'Teams_in_League', 'Home_Team_Goals_For_This_Far',\n",
    "            'Home_Team_Goals_Against_This_Far', 'Away_Team_Goals_For_This_Far',\n",
    "            'Away_Team_Goals_Against_This_Far', 'Home_Team_Points',\n",
    "            'Away_Team_Points', 'Away_Team_Winning_Streak',\n",
    "            'Home_Team_Unbeaten_Streak', 'Away_Team_Unbeaten_Streak', 'Elo_home',\n",
    "            'Elo_away', 'Home_Wins_This_Far', 'Home_Draws_This_Far',\n",
    "            'Home_Losses_This_Far', 'Away_Draws_This_Far',\n",
    "            'Home_Wins_This_Far_at_Home', 'Home_Draws_This_Far_at_Home',\n",
    "            'Home_Losses_This_Far_at_Home', 'Home_Draws_This_Far_Away',\n",
    "            'Away_Wins_This_Far_at_Home', 'Away_Draws_This_Far_at_Home',\n",
    "            'Away_Losses_This_Far_at_Home', 'Away_Wins_This_Far_Away',\n",
    "            'Away_Draws_This_Far_Away', 'Capacity', 'Home_Yellow',\n",
    "            'Away_Team_Yellows_This_Far', 'Away_Red', 'Home_Points_Per_Game',\n",
    "            'Home_Goals_Per_Game', 'Home_Goals_Against_Per_Game',\n",
    "            'Away_Points_Per_Game', 'Away_Goals_Per_Game',\n",
    "            'Away_Goals_Against_Per_Game', 'Away_Cards_Per_Game', 'Pitch_Match',\n",
    "            'League']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "while using other metrics such as SelectKBest with a chi-squared function and RandomForest to sort feature importances produced similar lists. Using this one was purely due to it producing the best results on the testing set. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grid Search (particularly with the GridSearchCV package) was used to find the best model after separating the dataset into train and test sets and then scaling them with the StandardScaler package. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression, Lasso, SGDRegressor, \\\n",
    "    RidgeClassifier, SGDClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
    "from sklearn.neural_network import MLPClassifier, MLPRegressor\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier, AdaBoostRegressor, \\\n",
    "    GradientBoostingClassifier, GradientBoostingRegressor, \\\n",
    "    RandomForestClassifier, RandomForestRegressor\n",
    "from xgboost import XGBClassifier, XGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [LinearRegression(),\n",
    "    KNeighborsClassifier(n_neighbors=151),\n",
    "    MLPClassifier(hidden_layer_sizes=(150, 100, 50), max_iter=1000,\n",
    "                  activation='tanh', solver='adam', random_state=1,\n",
    "                  learning_rate='adaptive'),\n",
    "    MLPRegressor(activation='tanh', alpha=0.1,\n",
    "       hidden_layer_sizes=(150, 100, 50),\n",
    "       learning_rate='adaptive', solver='sgd',\n",
    "       max_iter=1000),\n",
    "    DecisionTreeClassifier(random_state=1,\n",
    "    max_features=\"sqrt\",\n",
    "    max_depth=None),\n",
    "    DecisionTreeRegressor(criterion='squared_error',\n",
    "    max_depth=5),\n",
    "    Lasso(alpha=0.00023),\n",
    "    AdaBoostClassifier(learning_rate=1.0, n_estimators=10000),\n",
    "    AdaBoostRegressor(learning_rate=0.01, n_estimators=10000),\n",
    "    RandomForestClassifier(\n",
    "        criterion='entropy', max_depth=128,\n",
    "        max_features='log2', n_estimators=1024),\n",
    "    RandomForestRegressor(criterion='poisson',\n",
    "    max_depth=12, max_features='log2',\n",
    "    n_estimators=256),\n",
    "    GradientBoostingClassifier(criterion='friedman_mse',\n",
    "                               learning_rate=0.2, loss='log_loss',\n",
    "                               max_depth=8, max_features='sqrt',\n",
    "                               min_samples_leaf=0.1,\n",
    "                               min_samples_split=0.18,\n",
    "                               n_estimators=10, subsample=1),\n",
    "    GradientBoostingRegressor(criterion='friedman_mse',\n",
    "    learning_rate=0.2, loss='squared_error',\n",
    "    max_depth=8, max_features='log2',\n",
    "    min_samples_leaf=0.1,\n",
    "    min_samples_split=0.18,\n",
    "    n_estimators=10, subsample=1),\n",
    "    XGBClassifier(learning_rate=0.01, max_depth=6, n_estimators=324),\n",
    "    XGBRegressor(learning_rate=0.05, max_depth=4, n_estimators=220),\n",
    "    SGDClassifier(alpha=0.01, loss='log_loss', penalty='none'),\n",
    "    SGDRegressor(alpha=0.01, loss='squared_error', penalty='none'),\n",
    "    RidgeClassifier()\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above are the best hyper-parameters by score after roughly a day of training each model. By score, the best models were RandomForestClassifier and XGBClassifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def scale_array(df):\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(df)\n",
    "    X_sc = scaler.transform(df)\n",
    "    return X_sc\n",
    "\n",
    "def accuracy(confusion_matrix):\n",
    "    diagonal_sum = confusion_matrix.trace()\n",
    "    sum_of_all_elements = confusion_matrix.sum()\n",
    "    return diagonal_sum / sum_of_all_elements\n",
    "\n",
    "y = data['Result'].values\n",
    "X = data.drop(['Result', 'Date_New', 'Link'], inplace=False, axis=1)\n",
    "X.League = X.League.astype('category').cat.codes\n",
    "X_sc = scale_array(X[svm_cols])\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_sc, y, test_size=0.1)\n",
    "model = RandomForestClassifier(\n",
    "        criterion='entropy', max_depth=128,\n",
    "        max_features='log2', n_estimators=2048)\n",
    "model = model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "print(accuracy(cm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This gave an accuracy of around 0.53 which is passable. Afterwards, I iteratively tested removing older years from the dataset as they are unlikely to be reflective of modern football. Supported by testing, I decided to remove the matches played before the year 2000 and briefly trialed removing the eerste divisie before simply rescraping the data as it was poorly scraped initially."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3d597f4c481aa0f25dceb95d2a0067e73c0966dcbd003d741d821a7208527ecf"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
